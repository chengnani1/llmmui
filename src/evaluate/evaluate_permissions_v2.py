# -*- coding: utf-8 -*-
"""
æƒé™è¯†åˆ«æ•ˆæœè¯„æµ‹è„šæœ¬

è¾“å…¥ï¼š
  processed/
    fastbot-xxx/
      goal_labels.json
      results_permission_rule_only.json
      results_permission_llm_only.json
      results_permission_rule_llm.json

åŠŸèƒ½ï¼š
  - å¿½ç•¥ true_permissions ä¸ºç©ºçš„é“¾æ¡
  - å¯¹ä¸‰ç§æ–¹æ³•åˆ†åˆ«è®¡ç®—ï¼š
        Â· æ¯ä¸ª app çš„ Accuracy / Precision / Recall / F1
        Â· å…¨å±€æ±‡æ€»ï¼šæœ‰æ•ˆ app æ•°ã€æœ‰æ•ˆæƒé™é“¾æ•°ã€TP / FP / FNã€å…¨å±€ Accuracy / Precision / Recall / F1
"""

import os
import json
from collections import Counter

EVAL_FILES = {
    "rule_only": "results_permission_rule_only.json",
    "llm_only": "results_permission_llm_only.json",
    "rule_llm": "results_permission_rule_llm.json",
}


def load_json(path):
    if not os.path.exists(path):
        return None
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def eval_one_method(gt_labels, pred_results):
    """
    gt_labels: dict(chain_id â†’ true_permissions)
    pred_results: list({chain_id, predicted_permissions})

    è¿”å› metrics å­—å…¸ï¼ˆå•ä¸ª app çº§åˆ«ï¼‰
    """
    pred_map = {x["chain_id"]: x["predicted_permissions"] for x in pred_results}

    TP = 0
    FP = 0
    FN = 0

    per_perm = Counter()
    per_perm_TP = Counter()
    per_perm_FP = Counter()
    per_perm_FN = Counter()

    total = 0  # å‚ä¸è¯„æµ‹çš„é“¾æ¡æ•°ï¼ˆæ’é™¤ true_permissions ä¸ºç©ºçš„ï¼‰

    for cid, gt_perms in gt_labels.items():

        # è¿‡æ»¤æ‰ true_permissions ä¸ºç©ºçš„é“¾æ¡
        if not gt_perms:
            continue

        total += 1
        pred = pred_map.get(cid, [])

        gt_set = set(gt_perms)
        pred_set = set(pred)

        for p in gt_set:
            per_perm[p] += 1

        tp_set = gt_set & pred_set
        fp_set = pred_set - gt_set
        fn_set = gt_set - pred_set

        TP += len(tp_set)
        FP += len(fp_set)
        FN += len(fn_set)

        for p in tp_set:
            per_perm_TP[p] += 1
        for p in fp_set:
            per_perm_FP[p] += 1
        for p in fn_set:
            per_perm_FN[p] += 1

    accuracy = TP / (TP + FP + FN + 1e-6) if (TP + FP + FN) > 0 else 0.0
    precision = TP / (TP + FP + 1e-6) if (TP + FP) > 0 else 0.0
    recall = TP / (TP + FN + 1e-6) if (TP + FN) > 0 else 0.0
    f1 = 2 * precision * recall / (precision + recall + 1e-6) if (precision + recall) > 0 else 0.0

    return {
        "total_evaluated_chains": total,
        "TP": TP,
        "FP": FP,
        "FN": FN,
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1": f1,
        "per_permission_stats": {
            p: {
                "gt_count": per_perm[p],
                "TP": per_perm_TP[p],
                "FP": per_perm_FP[p],
                "FN": per_perm_FN[p],
                "precision": per_perm_TP[p] / (per_perm_TP[p] + per_perm_FP[p] + 1e-6),
                "recall": per_perm_TP[p] / (per_perm_TP[p] + per_perm_FN[p] + 1e-6),
            }
            for p in per_perm.keys()
        }
    }


def main(processed_root):
    all_apps = [
        d for d in os.listdir(processed_root)
        if d.startswith("fastbot-") and os.path.isdir(os.path.join(processed_root, d))
    ]

    print(f"\nğŸ“‚ æ‰¾åˆ° {len(all_apps)} ä¸ª app\n")

    # æ¯ç§æ–¹æ³•ï¼šæ”¶é›†æ¯ä¸ª app çš„ metrics
    results_summary = {
        "rule_only": [],
        "llm_only": [],
        "rule_llm": [],
    }

    for app in sorted(all_apps):
        app_dir = os.path.join(processed_root, app)

        gt = load_json(os.path.join(app_dir, "goal_labels.json"))
        if gt is None:
            print(f"âš  è·³è¿‡ï¼ˆæ— çœŸå®æ ‡ç­¾ï¼‰ï¼š{app}")
            continue

        # æ„å»º gt dict
        gt_map = {
            item["chain_id"]: item.get("true_permissions", [])
            for item in gt
            if isinstance(item, dict)
        }

        print(f"\n==============================")
        print(f"ğŸ“Œ è¯„æµ‹ APPï¼š{app}")

        for method, filename in EVAL_FILES.items():
            pred = load_json(os.path.join(app_dir, filename))
            if pred is None:
                print(f"  âš  {method} æ— ç»“æœï¼Œè·³è¿‡")
                continue

            metrics = eval_one_method(gt_map, pred)

            # å¦‚æœè¯¥ app åœ¨è¿™ä¸ªæ–¹æ³•ä¸‹æ²¡æœ‰æœ‰æ•ˆé“¾æ¡ï¼Œå°±ä¸è®¡å…¥ç»Ÿè®¡
            if metrics["total_evaluated_chains"] == 0:
                print(f"  âš  {method} åœ¨è¯¥ APP ä¸‹æ— æœ‰æ•ˆé“¾æ¡ï¼ˆå…¨éƒ¨ true_permissions ä¸ºç©ºï¼‰ï¼Œè·³è¿‡")
                continue

            results_summary[method].append(metrics)

            print(f"\n  ğŸ” æ–¹æ³•ï¼š{method}")
            print(f"     å‚ä¸è¯„æµ‹é“¾æ¡æ•°ï¼š{metrics['total_evaluated_chains']}")
            print(f"     TP={metrics['TP']}  FP={metrics['FP']}  FN={metrics['FN']}")
            print(f"     Accuracy = {metrics['accuracy']:.4f}")
            print(f"     Precision = {metrics['precision']:.4f}")
            print(f"     Recall = {metrics['recall']:.4f}")
            print(f"     F1 = {metrics['f1']:.4f}")

    # ======== è¾“å‡ºæ•´ä½“å¹³å‡ç»“æœ + å…¨å±€æ±‡æ€» ========
    print("\n\n==============================")
    print("ğŸ“Š **æœ€ç»ˆæ•´ä½“ç»“æœï¼ˆå¹³å‡ over all apps + å…¨å±€ç»Ÿè®¡ï¼‰**")
    print("==============================\n")

    for method, lst in results_summary.items():
        if not lst:
            continue

        # 1) æŒ‰ app å¹³å‡çš„æŒ‡æ ‡ï¼ˆä½ ç°åœ¨å·²ç»åœ¨çœ‹çš„é‚£ä¸€ç»„ï¼‰
        avg_acc = sum(x["accuracy"] for x in lst) / len(lst)
        avg_prec = sum(x["precision"] for x in lst) / len(lst)
        avg_rec = sum(x["recall"] for x in lst) / len(lst)
        avg_f1 = sum(x["f1"] for x in lst) / len(lst)

        # 2) å…¨å±€æ±‡æ€»ï¼ˆæ‰€æœ‰ app çš„ TP / FP / FN åŠ èµ·æ¥ï¼‰
        total_TP = sum(x["TP"] for x in lst)
        total_FP = sum(x["FP"] for x in lst)
        total_FN = sum(x["FN"] for x in lst)
        total_chains = sum(x["total_evaluated_chains"] for x in lst)
        valid_apps = len(lst)

        global_acc = total_TP / (total_TP + total_FP + total_FN + 1e-6) if (total_TP + total_FP + total_FN) > 0 else 0.0
        global_prec = total_TP / (total_TP + total_FP + 1e-6) if (total_TP + total_FP) > 0 else 0.0
        global_rec = total_TP / (total_TP + total_FN + 1e-6) if (total_TP + total_FN) > 0 else 0.0
        global_f1 = 2 * global_prec * global_rec / (global_prec + global_rec + 1e-6) if (global_prec + global_rec) > 0 else 0.0

        print(f"\nâ­ æ–¹æ³•ï¼š{method}")
        print(f"   â–¶ æœ‰æ•ˆå‚ä¸è¯„æµ‹çš„ APP æ•°ï¼š{valid_apps}")
        print(f"   â–¶ æœ‰æ•ˆæƒé™é“¾æ€»æ•°ï¼ˆtrue_permissions éç©ºï¼‰ï¼š{total_chains}")
        print(f"   â–¶ å…¨å±€ TP={total_TP}  FP={total_FP}  FN={total_FN}")

        print(f"   â€”â€” æŒ‰ app å¹³å‡æŒ‡æ ‡ â€”â€”")
        print(f"      Avg Accuracy  = {avg_acc:.4f}")
        print(f"      Avg Precision = {avg_prec:.4f}")
        print(f"      Avg Recall    = {avg_rec:.4f}")
        print(f"      Avg F1        = {avg_f1:.4f}")

        print(f"   â€”â€” å…¨å±€ micro æŒ‡æ ‡ï¼ˆæ‰€æœ‰æ ·æœ¬ä¸€èµ·ç®—ï¼‰ â€”â€”")
        print(f"      Global Accuracy  = {global_acc:.4f}")
        print(f"      Global Precision = {global_prec:.4f}")
        print(f"      Global Recall    = {global_rec:.4f}")
        print(f"      Global F1        = {global_f1:.4f}")


if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("ç”¨æ³•ï¼š python evaluate_permissions.py <processed_dir>")
        sys.exit(1)

    processed_root = sys.argv[1]
    main(processed_root)