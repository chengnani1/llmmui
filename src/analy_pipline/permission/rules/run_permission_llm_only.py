# -*- coding: utf-8 -*-
"""
LLM-only permission recognition (PERMISSION-AWARE VERSION)

Input :
  /Users/charon/Downloads/code/processed/<app>/result.json

Output:
  /Users/charon/Downloads/code/processed/<app>/result_permission_llm.json

LLM is ONLY used for semantic permission reasoning.
NO rule-based final decision.
"""

import os
import json
import requests
from typing import List, Dict, Any

from permission_config import ALL_DANGEROUS_PERMS

# =========================================================
# CONFIG
# =========================================================

ROOT_DIR = "/Users/charon/Downloads/code/processed"

VLLM_URL = "http://localhost:8003/v1/chat/completions"
MODEL_NAME = "Qwen2.5-7B"
TIMEOUT = 40

# =========================================================
# Permission-aware feature extraction
# =========================================================

PERMISSION_RID_KEYS = [
    "permission_group_title",
    "permission_allow",
    "permission_deny",
    "permissioncontroller",
    "miui"
]

ACTION_WORDS = ["å…è®¸", "æ‹’ç»"]

SCENE_HINT_WORDS = [
    "å½•åˆ¶", "éŸ³é¢‘", "æ‹æ‘„", "ç›¸æœº", "è§†é¢‘",
    "æ–‡ä»¶", "ä¿å­˜", "è¯»å–", "æœ¬åœ°"
]


def extract_permission_dialogs(ui_granting: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    dialogs = []

    for step in ui_granting:
        widgets = step.get("feature", {}).get("widgets", [])
        title = None
        actions = []
        app = None

        for w in widgets:
            rid = (w.get("resource-id") or "").lower()
            txt = (w.get("text") or "").strip()

            if "permission_group_title" in rid and txt:
                title = txt

            if any(a in txt for a in ACTION_WORDS):
                actions.append(txt)

            if "permission_applicant" in rid and txt:
                app = txt

        if title:
            dialogs.append({
                "title": title,
                "actions": list(set(actions)),
                "app": app or ""
            })

    return dialogs


def extract_scene_keywords(ui_part: Dict[str, Any], max_k: int = 5) -> List[str]:
    kws = []
    widgets = ui_part.get("feature", {}).get("widgets", [])

    for w in widgets:
        txt = (w.get("text") or "").strip()
        if any(k in txt for k in SCENE_HINT_WORDS):
            kws.append(txt)
        if len(kws) >= max_k:
            break

    return kws


def build_semantic_summary(ui_item: Dict[str, Any]) -> Dict[str, Any]:
    return {
        "permission_dialogs": extract_permission_dialogs(
            ui_item.get("ui_granting", [])
        ),
        "before_scene_keywords": extract_scene_keywords(
            ui_item.get("ui_before_grant", {})
        ),
        "after_scene_keywords": extract_scene_keywords(
            ui_item.get("ui_after_grant", {})
        )
    }

# =========================================================
# LLM call
# =========================================================

def call_llm(prompt: str) -> str:
    try:
        resp = requests.post(
            VLLM_URL,
            json={
                "model": MODEL_NAME,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0,
            },
            timeout=TIMEOUT,
        )
        resp.raise_for_status()
        return resp.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"[LLM ERROR] {e}")
        return ""


def llm_predict_permissions(summary: Dict[str, Any]) -> List[str]:
    cand_text = "\n".join(f"- {p}" for p in ALL_DANGEROUS_PERMS)

    prompt = f"""
ä½ æ˜¯ä¸€åå®‰å“æƒé™åˆ†æä¸“å®¶ã€‚

ä¸‹é¢æ˜¯ä¸€æ¬¡æƒé™ç”³è¯·é“¾çš„ç»“æ„åŒ–ä¿¡æ¯ï¼ˆå·²å»é™¤æ— å…³ UI å†…å®¹ï¼‰ï¼š

æƒé™å¼¹çª—ï¼š
{json.dumps(summary["permission_dialogs"], ensure_ascii=False)}

æƒé™å‰åœºæ™¯å…³é”®è¯ï¼š
{summary["before_scene_keywords"]}

æƒé™ååœºæ™¯å…³é”®è¯ï¼š
{summary["after_scene_keywords"]}

å€™é€‰å±é™©æƒé™åˆ—è¡¨ï¼š
{cand_text}

è¯·åˆ¤æ–­è¯¥æƒé™ç”³è¯·æœ€å¯èƒ½æ¶‰åŠçš„æƒé™ã€‚
å¦‚æœæ— æ³•ç¡®å®šï¼Œè¯·è¿”å›ç©ºæ•°ç»„ã€‚

ä¸¥æ ¼æŒ‰ JSON è¾“å‡ºï¼š
{{"permissions": ["PERM1", "PERM2"]}}
"""

    raw = call_llm(prompt)

    try:
        obj = json.loads(raw)
        perms = obj.get("permissions", [])
        return [p for p in perms if p in ALL_DANGEROUS_PERMS]
    except Exception:
        return []

# =========================================================
# Process one app
# =========================================================

def process_one_app(app_dir: str):
    print(f"\nğŸ“Œ LLM-only PROCESS APP: {app_dir}")

    path = os.path.join(app_dir, "result.json")
    if not os.path.exists(path):
        print("  âŒ skip (no result.json)")
        return

    data = json.load(open(path, "r", encoding="utf-8"))
    outputs = []

    for idx, ui_item in enumerate(data):
        chain_id = ui_item.get("chain_id", idx)

        summary = build_semantic_summary(ui_item)
        perms = llm_predict_permissions(summary)

        outputs.append({
            "chain_id": chain_id,
            "predicted_permissions": perms,
            "files": {
                "before": ui_item["ui_before_grant"]["file"],
                "granting": [g["file"] for g in ui_item.get("ui_granting", [])],
                "after": ui_item["ui_after_grant"]["file"]
            }
        })

        print(f"  [LLM] chain {chain_id}: {perms}")

    out_path = os.path.join(app_dir, "result_permission_llm.json")
    json.dump(outputs, open(out_path, "w", encoding="utf-8"),
              indent=2, ensure_ascii=False)

    print(f"  âœ… WRITE DONE: {out_path}")

# =========================================================
# Main
# =========================================================

def main():
    print("ğŸš€ LLM-only Permission Recognition (Permission-aware)")
    print("ğŸ“‚ ROOT_DIR =", ROOT_DIR)

    for d in sorted(os.listdir(ROOT_DIR)):
        app_dir = os.path.join(ROOT_DIR, d)
        if not os.path.isdir(app_dir):
            continue
        process_one_app(app_dir)

    print("\nğŸ‰ ALL DONE")

if __name__ == "__main__":
    main()