# -*- coding: utf-8 -*-
"""
å¼ºåŒ–ç‰ˆæƒé™è¯†åˆ«æ ¸å¿ƒæ¨¡å—ï¼ˆè§„åˆ™ä¼˜å…ˆï¼ŒLLM å…œåº•ï¼‰
"""

import json
import re
from typing import Dict, Any, List, Optional
import requests # type: ignore
import os

from permission_config import BASE_PERMISSION_TABLE, ALL_DANGEROUS_PERMS

# ========================= Debug è¾“å‡ºç›®å½• =========================
DEBUG_SAVE = True
DEBUG_FILENAME = "results_permission_debug.json"

# ========================= æœ¬åœ° LLM é…ç½® =========================
VLLM_URL = "http://localhost:8001/v1/chat/completions"
MODEL_NAME = "Qwen3-VL-30B-A3B"
LLM_TIMEOUT = 40

# ========================= å·¥å…·å‡½æ•° =========================

def _normalize_text(t: str) -> str:
    if not t:
        return ""
    t = re.sub(r"\s+", "", t)
    return t.lower()


def _extract_widget_all_text(w: Dict[str, Any]) -> List[str]:
    """
    ä» UI æ§ä»¶æå–æ‰€æœ‰å¯èƒ½çš„æ–‡æœ¬æ¥æºï¼ˆXML + OCR æ··åˆåœºæ™¯ç¨³ä¸€ç‚¹ï¼‰
    """
    fields = ["text", "content-desc", "description", "hint_text"]
    out: List[str] = []
    for k in fields:
        t = w.get(k)
        if t and isinstance(t, str):
            out.append(t)
    return out


def _collect_frames_widgets(ui_item: Dict[str, Any],
                            top_k_widgets: int = 5,
                            max_frames: int = 5) -> List[Dict[str, Any]]:
    """
    ä» before/granting/after é‡Œé¢æ”¶é›†éƒ¨åˆ†æ§ä»¶ï¼Œç”¨äº LLM åˆ†æä¸Šä¸‹æ–‡ã€‚
    """
    frames: List[Dict[str, Any]] = []

    def _add(tag: str, feature: Optional[Dict[str, Any]]):
        if not feature:
            return
        ws = feature.get("widgets") or []
        if not ws:
            return
        frames.append({"tag": tag, "widgets": ws[:top_k_widgets]})

    _add("before", ui_item.get("ui_before_grant", {}).get("feature"))

    for i, step in enumerate(ui_item.get("ui_granting", [])):
        if len(frames) >= max_frames - 1:
            break
        _add(f"granting_{i}", step.get("feature"))

    _add("after", ui_item.get("ui_after_grant", {}).get("feature"))

    return frames[:max_frames]


def _collect_texts_for_rule(ui_item: Dict[str, Any]) -> List[str]:
    """
    è§„åˆ™åŒ¹é…ç”¨ï¼š**é‡ç‚¹ä» feature["text"] é‡Œæ”¶æ–‡æœ¬**ï¼ˆä½ çš„ result.json å·²ç»é¢„å¤„ç†å¥½çš„ï¼‰ã€‚
    """
    texts: List[str] = []

    # before
    bf = ui_item.get("ui_before_grant", {}).get("feature", {}) or {}
    t = bf.get("text", "")
    if isinstance(t, list):
        texts.extend([str(x) for x in t if x])
    elif t:
        texts.append(str(t))

    # granting
    for step in ui_item.get("ui_granting", []):
        ft = step.get("feature", {}) or {}
        t = ft.get("text", "")
        if isinstance(t, list):
            texts.extend([str(x) for x in t if x])
        elif t:
            texts.append(str(t))

    # after
    af = ui_item.get("ui_after_grant", {}).get("feature", {}) or {}
    t = af.get("text", "")
    if isinstance(t, list):
        texts.extend([str(x) for x in t if x])
    elif t:
        texts.append(str(t))

    return texts


def _build_llm_full_text(frames: List[Dict[str, Any]]) -> str:
    """
    LLM ç”¨ï¼šå°½é‡æ‹¼æ¥æ§ä»¶æ–‡æœ¬ï¼Œå¹¶ä¿ç•™ frame æ ‡ç­¾ã€‚
    """
    parts: List[str] = []
    for i, f in enumerate(frames):
        texts: List[str] = []
        for w in f["widgets"]:
            texts.extend(_extract_widget_all_text(w))
        if texts:
            parts.append(f"[{f['tag']} STEP {i}] " + " ".join(texts))
    return " ".join(parts)


# ========================= è°ƒè¯•å®¹å™¨ =========================
LLM_DEBUG_LOG: List[Dict[str, Any]] = []


def _call_llm(prompt: str) -> str:
    try:
        resp = requests.post(
            VLLM_URL,
            json={
                "model": MODEL_NAME,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0,
            },
            timeout=LLM_TIMEOUT,
        )
        resp.raise_for_status()
        out = resp.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        out = ""
        print(f"[LLM ERROR] {e}")

    LLM_DEBUG_LOG.append({"prompt": prompt, "output": out})
    return out


def _llm_select_permissions(full_text: str,
                            candidate: List[str]) -> List[str]:
    if not candidate:
        return []

    perm_list = "\n".join(f"- {p}" for p in candidate)

    prompt = f"""
ä½ æ˜¯ä¸€åå®‰å“æƒé™åˆ†æä¸“å®¶ï¼ŒåŸºäºä»¥ä¸‹æ§ä»¶æ–‡æœ¬ï¼Œä»å€™é€‰æƒé™ä¸­é€‰æ‹©æœ€å¯èƒ½çš„æƒé™1ä¸ªæˆ–å¤šä¸ªã€‚

å€™é€‰æƒé™ï¼š
{perm_list}

æ§ä»¶æ–‡æœ¬ï¼š
{full_text}

ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
{{"permissions": ["PERM1", "PERM2"]}}
"""

    raw = _call_llm(prompt)
    try:
        obj = json.loads(raw)
        out = obj.get("permissions", [])
    except Exception:
        return []

    cand = set(candidate)
    return [p for p in out if p in cand]


# ========================= ä¸»å‡½æ•° =========================

def recognize_permission(ui_item: Dict[str, Any],
                         vendor: str = "MI",
                         use_llm: bool = True) -> List[str]:
    """
    ä¼˜å…ˆä»æ§ä»¶æ–‡æœ¬ä¸­æŒ‰è§„åˆ™åŒ¹é…æƒé™ï¼›
    åŒ¹é…ä¸åˆ° / å¤šæ¡å†²çªæ—¶ï¼Œå†è°ƒç”¨ LLMã€‚
    """

    # ---- 1. å–å‡º vendor å¯¹åº”çš„è§„åˆ™è¡¨ï¼ˆæ°¸è¿œæ˜¯ dictï¼‰----
    vendor_table = BASE_PERMISSION_TABLE.get(vendor)
    if vendor_table is None:
        # å…œåº•ï¼šæœªçŸ¥å‚å•†ç”¨å°ç±³è§„åˆ™
        vendor_table = BASE_PERMISSION_TABLE["MI"]

    # ---- 2. æ”¶é›†æ–‡æœ¬ï¼ˆXML + OCR éƒ½åœ¨ feature["text"] é‡Œï¼‰----
    raw_texts = _collect_texts_for_rule(ui_item)
    all_texts = [_normalize_text(t) for t in raw_texts if t]

    # ---- 3. è§„åˆ™åŒ¹é… ----
    matches = []
    for zh, perms in vendor_table.items():   # â˜… è¿™é‡Œ vendor_table ä¸€å®šæ˜¯ dictï¼Œä¸ä¼šå†æ˜¯ set
        pat = _normalize_text(zh)
        for t in all_texts:
            if pat and pat in t:
                matches.append((zh, perms))
                break

    # å•è§„åˆ™ â†’ ç›´æ¥è¿”å›
    if len(matches) == 1:
        return sorted(set(matches[0][1]))

    # å¤šè§„åˆ™ â†’ ç”¨ LLM å†³ç­–ï¼ˆå€™é€‰é›†åªåœ¨å¤šè§„åˆ™æ—¶æ‰è¿› LLMï¼‰
    if len(matches) > 1:
        candidate = sorted({p for _, ps in matches for p in ps})
        if use_llm:
            frames = _collect_frames_widgets(ui_item)
            full_text = _build_llm_full_text(frames) or " ".join(all_texts)
            chosen = _llm_select_permissions(full_text, candidate)
            return chosen or candidate
        return candidate

    # ---- 4. å®Œå…¨åŒ¹é…ä¸åˆ° â†’ èµ° LLM fallback ----
    if use_llm:
        frames = _collect_frames_widgets(ui_item)
        full_text = _build_llm_full_text(frames) or " ".join(all_texts)
        return _llm_select_permissions(full_text, ALL_DANGEROUS_PERMS)

    return []


def save_llm_debug(app_dir: str):
    if not DEBUG_SAVE:
        return
    path = os.path.join(app_dir, DEBUG_FILENAME)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(LLM_DEBUG_LOG, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“ å·²ä¿å­˜ LLM è°ƒè¯•æ—¥å¿—è‡³ {path}")